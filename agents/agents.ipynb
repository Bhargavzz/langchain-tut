{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2240ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "# wiki=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "from langchain_core.tools import Tool\n",
    "import wikipedia\n",
    "wiki_tool = Tool (\n",
    "    name=\"Wikepedia\" ,\n",
    "    func= lambda q: wikipedia.run(q),\n",
    "    description=\"Useful for when you need to look up a topic or person on Wikipedia.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faea2410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wikepedia'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43db295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\vishn\\AppData\\Local\\Temp\\ipykernel_19676\\1377896551.py:11: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000024EE230C2F0>, search_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/docs/\")\n",
    "\n",
    "docs=loader.load()\n",
    "\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "embeddings=HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "vectordb=FAISS.from_documents(documents,embedding=embeddings)\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80355821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(\n",
    "                        retriever=retriever,\n",
    "                        name=\"langsmith_search\",\n",
    "                      description=\"Search for information about LangSmith,For any question about LangSmith, use this tool to find the answer from the documentation.\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88814125",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81373eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv_search'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Arxiv tool\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "arxiv_tool=Tool (\n",
    "    name=\"arxiv_search\",\n",
    "    func= lambda q: arxiv_wrapper.run(q),\n",
    "    description=\"Search Arxiv for academic papaers.\"\n",
    ")\n",
    "arxiv_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee0bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki_tool,arxiv_tool,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d61eff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='gemma2:2b')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm=ChatOllama(model=\"gemma2:2b\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25faa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Deprecated way to get prompt\n",
    "\n",
    "\n",
    "\n",
    "# from langchain_classic import hub\n",
    "# #Get the prompt to use - you can modify this!\n",
    "\n",
    "# prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "# prompt.messages\n",
    "\n",
    "\n",
    "\n",
    "##current way to get prompt\n",
    "\n",
    "# from langchain_core.messages import SystemMessage\n",
    "\n",
    "# prompt=SystemMessage(\n",
    "#     content=\"You are a helpful AI agent that uses tools to answer user questions.\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b39a63fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "functools.partial(<function _get_relevant_documents at 0x0000024EBB02D4E0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000024EE230C2F0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content') is not a module, class, method, or function.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- AGENT SETUP USING LCEL (new LangChain way) ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_agent\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m agent = \u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a helpful AI agent that uses tools to answer user questions.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Chatbot langchain\\venv\\Lib\\site-packages\\langchain\\agents\\factory.py:775\u001b[39m, in \u001b[36mcreate_agent\u001b[39m\u001b[34m(model, tools, system_prompt, middleware, response_format, state_schema, context_schema, checkpointer, store, interrupt_before, interrupt_after, debug, name, cache)\u001b[39m\n\u001b[32m    771\u001b[39m available_tools = middleware_tools + regular_tools\n\u001b[32m    773\u001b[39m \u001b[38;5;66;03m# Only create ToolNode if we have client-side tools\u001b[39;00m\n\u001b[32m    774\u001b[39m tool_node = (\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m     \u001b[43mToolNode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mavailable_tools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrap_tool_call\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrap_tool_call_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m        \u001b[49m\u001b[43mawrap_tool_call\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawrap_tool_call_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m available_tools\n\u001b[32m    781\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    782\u001b[39m )\n\u001b[32m    784\u001b[39m \u001b[38;5;66;03m# Default tools for ModelRequest initialization\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[38;5;66;03m# Use converted BaseTool instances from ToolNode (not raw callables)\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Include built-ins and converted tools (can be changed dynamically by middleware)\u001b[39;00m\n\u001b[32m    787\u001b[39m \u001b[38;5;66;03m# Structured tools are NOT included - they're added dynamically based on response_format\u001b[39;00m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tool_node:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Chatbot langchain\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:766\u001b[39m, in \u001b[36mToolNode.__init__\u001b[39m\u001b[34m(self, tools, name, tags, handle_tool_errors, messages_key, wrap_tool_call, awrap_tool_call)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28mself\u001b[39m._tools_by_name[tool_.name] = tool_\n\u001b[32m    765\u001b[39m \u001b[38;5;66;03m# Build injected args mapping once during initialization in a single pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28mself\u001b[39m._injected_args[tool_.name] = \u001b[43m_get_all_injected_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Chatbot langchain\\venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:1801\u001b[39m, in \u001b[36m_get_all_injected_args\u001b[39m\u001b[34m(tool)\u001b[39m\n\u001b[32m   1798\u001b[39m schema_annotations = get_all_basemodel_annotations(full_schema)\n\u001b[32m   1800\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(tool, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(tool, \u001b[33m\"\u001b[39m\u001b[33mcoroutine\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1801\u001b[39m func_annotations = \u001b[43mget_type_hints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_extras\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m   1803\u001b[39m \u001b[38;5;66;03m# Combine both annotation sources, preferring schema annotations\u001b[39;00m\n\u001b[32m   1804\u001b[39m \u001b[38;5;66;03m# In the future, we might want to add more restrictions here...\u001b[39;00m\n\u001b[32m   1805\u001b[39m all_annotations = {**func_annotations, **schema_annotations}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\typing.py:2484\u001b[39m, in \u001b[36mget_type_hints\u001b[39m\u001b[34m(obj, globalns, localns, include_extras)\u001b[39m\n\u001b[32m   2482\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[32m   2483\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2484\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m is not a module, class, method, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2485\u001b[39m                         \u001b[33m'\u001b[39m\u001b[33mor function.\u001b[39m\u001b[33m'\u001b[39m.format(obj))\n\u001b[32m   2486\u001b[39m hints = \u001b[38;5;28mdict\u001b[39m(hints)\n\u001b[32m   2487\u001b[39m type_params = \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33m__type_params__\u001b[39m\u001b[33m\"\u001b[39m, ())\n",
      "\u001b[31mTypeError\u001b[39m: functools.partial(<function _get_relevant_documents at 0x0000024EBB02D4E0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000024EE230C2F0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content') is not a module, class, method, or function."
     ]
    }
   ],
   "source": [
    "# --- AGENT SETUP USING LCEL (new LangChain way) ---\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful AI agent that uses tools to answer user questions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent Execution\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor=AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d56fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
